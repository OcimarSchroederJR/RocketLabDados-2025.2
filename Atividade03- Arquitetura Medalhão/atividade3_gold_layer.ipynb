{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a646b337-6bfe-4bab-b4e3-908aad879243",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "try:\n",
    "    # 1. Carregar tabelas da camada Silver\n",
    "    df_pedidos_total = spark.table(\"medalhao.silver.pedido_total\")\n",
    "    df_consumidores = spark.table(\"medalhao.silver.ft_consumidores\")\n",
    "\n",
    "    # 2. Juntar (join) as fontes de dados\n",
    "    # (ft_pedido_total já tem id_consumidor, então o join é simples)\n",
    "    df_joined = df_pedidos_total.join(\n",
    "        df_consumidores,\n",
    "        on=\"id_consumidor\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # 3. Selecionar e renomear colunas para a tabela fato\n",
    "    # (Conforme especificado na tabela do PDF)\n",
    "    df_gold = df_joined.select(\n",
    "        F.col(\"id_pedido\"),\n",
    "        F.col(\"id_consumidor\"),\n",
    "        F.col(\"valor_total_pago_brl\").alias(\"valor_total_pedido_brl\"),\n",
    "        F.col(\"cidade\"),\n",
    "        F.col(\"estado\"),\n",
    "        F.col(\"data_pedido\")\n",
    "    )\n",
    "\n",
    "    # 4. Salvar a nova tabela fato na camada Gold\n",
    "    df_gold.write.mode(\"overwrite\").saveAsTable(\"medalhao.gold.ft_vendas_consumidor_local\")\n",
    "    \n",
    "    print(\"Tabela medalhao.gold.ft_vendas_consumidor_local criada.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"falha ao processar gold.ft_vendas_consumidor_local: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b47c6976-1198-4799-a2b7-26c78dd0bf0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Query SQL para criar a view agregada\n",
    "query_view = \"\"\"\n",
    "    CREATE OR REPLACE VIEW medalhao.gold.view_total_compras_por_consumidor AS\n",
    "    SELECT \n",
    "        cidade,\n",
    "        estado,\n",
    "        COUNT(id_pedido) AS quantidade_vendas,\n",
    "        SUM(valor_total_pedido_brl) AS valor_total_localidade\n",
    "    FROM medalhao.gold.ft_vendas_consumidor_local\n",
    "    GROUP BY cidade, estado\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    spark.sql(query_view)\n",
    "    print(\"view medalhao.gold.view_total_compras_por_consumidor criada.\")\n",
    "except Exception as e:\n",
    "    print(f\"erro em 1.2: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "1d8b9d54-c033-41c9-854e-84902f6680d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Validando 1.2: Total de vendas por estado\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        estado,\n",
    "        SUM(valor_total_localidade) AS total_vendas\n",
    "    FROM medalhao.gold.view_total_compras_por_consumidor\n",
    "    GROUP BY estado\n",
    "    ORDER BY total_vendas DESC\n",
    "    LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "806ffa51-09c8-4447-a917-dd5b28b8131c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "try:\n",
    "    # Carregar tabelas silver\n",
    "    df_pedidos = spark.table(\"medalhao.silver.ft_pedidos\")\n",
    "    df_consumidores = spark.table(\"medalhao.silver.ft_consumidores\")\n",
    "    df_itens = spark.table(\"medalhao.silver.ft_itens_pedidos\")\n",
    "\n",
    "    # Preparar fontes para o join\n",
    "    \n",
    "    # Localização do consumidor\n",
    "    df_loc_consumidor = df_consumidores.select(\"id_consumidor\", \"cidade\", \"estado\")\n",
    "    \n",
    "    # Dados de entrega do pedido\n",
    "    df_dados_entrega = df_pedidos.select(\n",
    "        \"id_pedido\",\n",
    "        \"id_consumidor\",\n",
    "        \"entrega_no_prazo\",\n",
    "        \"tempo_entrega_dias\",\n",
    "        \"tempo_entrega_estimado_dias\"\n",
    "    )\n",
    "    \n",
    "    # Vendedor de cada pedido (pegando distintos para evitar duplicação\n",
    "    # se o mesmo vendedor tiver múltiplos itens no mesmo pedido)\n",
    "    df_vendedores_pedido = df_itens.select(\"id_pedido\", \"id_vendedor\").distinct()\n",
    "\n",
    "    # Juntar as três fontes\n",
    "    df_gold = df_dados_entrega.join(\n",
    "        df_loc_consumidor,\n",
    "        \"id_consumidor\",\n",
    "        \"left\"\n",
    "    ).join(\n",
    "        df_vendedores_pedido,\n",
    "        \"id_pedido\",\n",
    "        \"left\"\n",
    "    )\n",
    "    \n",
    "    # Selecionar colunas finais para a tabela fato\n",
    "    df_gold_final = df_gold.select(\n",
    "        \"id_pedido\",\n",
    "        \"id_vendedor\",\n",
    "        \"id_consumidor\",\n",
    "        \"entrega_no_prazo\",\n",
    "        \"tempo_entrega_dias\",\n",
    "        \"tempo_entrega_estimado_dias\",\n",
    "        \"cidade\",\n",
    "        \"estado\"\n",
    "    )\n",
    "\n",
    "    # Salvar na camada Gold\n",
    "    df_gold_final.write.mode(\"overwrite\").saveAsTable(\"medalhao.gold.ft_atrasos_pedidos_local_vendedor\")\n",
    "    \n",
    "    print(\"tabela medalhao.gold.ft_atrasos_pedidos_local_vendedor criada.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"erro em 2.1: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "28d42018-6101-4233-ac94-63cb0dd645e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Query SQL para criar a view \n",
    "query_view_2_2_1 = \"\"\"\n",
    "    CREATE OR REPLACE VIEW medalhao.gold.view_tempo_medio_entrega_localidade AS\n",
    "    SELECT \n",
    "        cidade,\n",
    "        estado,\n",
    "        \n",
    "        -- Média do tempo real\n",
    "        AVG(tempo_entrega_dias) AS tempo_medio_entrega,\n",
    "        \n",
    "        -- Média do tempo estimado\n",
    "        AVG(tempo_entrega_estimado_dias) AS tempo_medio_estimado,\n",
    "        \n",
    "        -- Indicador se a média real é maior que a estimada\n",
    "        CASE\n",
    "            WHEN AVG(tempo_entrega_dias) > AVG(tempo_entrega_estimado_dias) THEN 'SIM'\n",
    "            ELSE 'NÃO'\n",
    "        END AS entrega_maior_que_estimado\n",
    "        \n",
    "    FROM medalhao.gold.ft_atrasos_pedidos_local_vendedor\n",
    "    WHERE tempo_entrega_dias IS NOT NULL -- Ignorar pedidos não entregues\n",
    "    GROUP BY cidade, estado\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    spark.sql(query_view_2_2_1)\n",
    "    print(\"view medalhao.gold.view_tempo_medio_entrega_localidade criada.\")\n",
    "except Exception as e:\n",
    "    print(f\"erro em 2.2.1: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b243a1b1-408e-4c67-be50-ecdab6490f23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Query SQL para criar a view \n",
    "query_view_2_2_2 = \"\"\"\n",
    "    CREATE OR REPLACE VIEW medalhao.gold.view_vendedor_pontualidade AS\n",
    "    SELECT \n",
    "        id_vendedor,\n",
    "        \n",
    "        -- Total de pedidos do vendedor\n",
    "        COUNT(id_pedido) AS total_pedidos,\n",
    "        \n",
    "        -- Total de pedidos com atraso (onde entrega_no_prazo = 'Não')\n",
    "        SUM(\n",
    "            CASE \n",
    "                WHEN entrega_no_prazo = 'Não' THEN 1\n",
    "                ELSE 0 \n",
    "            END\n",
    "        ) AS total_atrasados,\n",
    "        \n",
    "        -- Percentual de atraso (total_atrasados / total_pedidos)\n",
    "        (\n",
    "            SUM(\n",
    "                CASE \n",
    "                    WHEN entrega_no_prazo = 'Não' THEN 1\n",
    "                    ELSE 0 \n",
    "                END\n",
    "            ) / COUNT(id_pedido)\n",
    "        ) * 100 AS percentual_atraso\n",
    "        \n",
    "    FROM medalhao.gold.ft_atrasos_pedidos_local_vendedor\n",
    "    WHERE id_vendedor IS NOT NULL -- Ignorar pedidos sem vendedor\n",
    "    GROUP BY id_vendedor\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    spark.sql(query_view_2_2_2)\n",
    "    print(\"view medalhao.gold.view_vendedor_pontualidade criada.\")\n",
    "except Exception as e:\n",
    "    print(f\"erro em 2.2.2: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "atividade3_gold_layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
